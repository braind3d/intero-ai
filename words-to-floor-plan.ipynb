{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Words to Floor Plan (W2FP) Generative adversarial network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports\n",
    "Packages and libraries used through-out the project."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.8.0'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model, layers, losses\n",
    "from IPython import display\n",
    "\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyper-parametes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "IMG_ROOT=\"./data/images/\"\n",
    "\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=50\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=128\n",
    "VOCAB_SIZE = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Text vectorization\n",
    "Defining text conversion utility, which processes text to be appropriate for neural network input."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 14:55:26.614882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:26.645558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:26.645722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:26.646423: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-20 14:55:26.646835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:26.646990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:26.647121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:27.196294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:27.196513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:27.196645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 14:55:27.196806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6605 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "int_vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open(\"data/labels.json\") as file:\n",
    "    labels_json = json.load(file)\n",
    "\n",
    "filelist = []\n",
    "labels_array = []\n",
    "\n",
    "for key, value in labels_json.items():\n",
    "    filelist.append(key)\n",
    "    labels_array.append(value)\n",
    "\n",
    "labels_dataset = tf.convert_to_tensor(labels_array)\n",
    "int_vectorize_layer.adapt(labels_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "images_array = []\n",
    "for name in filelist:\n",
    "    image = Image.open(IMG_ROOT + name)\n",
    "    image_w, image_h = image.size\n",
    "\n",
    "    padded_image = Image.new(image.mode, (64, 64), (255, 255, 255))\n",
    "    offset = ((64 - image_w) // 2, (64 - image_h) // 2)\n",
    "    padded_image.paste(image, offset)\n",
    "\n",
    "    flat_image = []\n",
    "\n",
    "    for y in range(64):\n",
    "        for x in range(64):\n",
    "            r, g, b = padded_image.getpixel((x, y))\n",
    "            if r == 0 and g == 0 and b == 0:\n",
    "                flat_image.append(-1)\n",
    "            elif r == 255 and g == 0 and b == 0:\n",
    "                flat_image.append(-2/3)\n",
    "            elif r == 255 and g == 232 and b == 0:\n",
    "                flat_image.append(-1/3)\n",
    "            elif r == 0 and g == 0 and b == 255:\n",
    "                flat_image.append(0)\n",
    "            elif r == 0 and g == 255 and b == 0:\n",
    "                flat_image.append(1/3)\n",
    "            elif r == 0 and g == 255 and b == 255:\n",
    "                flat_image.append(2/3)\n",
    "            elif r == 255 and g == 255 and b == 255:\n",
    "                flat_image.append(1)\n",
    "\n",
    "    flat_image = np.array(flat_image).reshape(64, 64, 1)\n",
    "    images_array.append(flat_image)\n",
    "\n",
    "\n",
    "images_dataset = tf.convert_to_tensor(images_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generator neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_generator_model() -> Model:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(int_vectorize_layer)\n",
    "\n",
    "    # `VOCAB_SIZE + 1` since `0` is used additionally for padding.\n",
    "    model.add(layers.Embedding(VOCAB_SIZE + 1, 128, input_length=MAX_SEQUENCE_LENGTH, mask_zero=True)),\n",
    "    model.add(layers.Conv1D(64, 5, padding=\"same\", activation=\"relu\", strides=2))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(8*8*64))\n",
    "\n",
    "    model.add(layers.Reshape((8, 8, 64)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 128, 128)          16512     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 64, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              266240    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 512)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 512)        2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 256)        3276800   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 128)      819200    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 1)        1600      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,449,216\n",
      "Trainable params: 5,447,296\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = create_generator_model()\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Discriminator neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def create_discriminator_model() -> Model:\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', use_bias=False, input_shape=[64, 64, 1]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', use_bias=False, input_shape=[64, 32, 32]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False, input_shape=[128, 16, 16]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', use_bias=False, input_shape=[256, 8, 8]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(512, (4, 4), strides=(1, 1), padding='same', use_bias=False, input_shape=[512, 4, 4]))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131072    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         2097152   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 512)         4194304   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,959,873\n",
      "Trainable params: 6,957,953\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = create_discriminator_model()\n",
    "discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimizer functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(labels_dataset, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(image_dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for batch in image_dataset:\n",
    "      train_step(batch)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(images_dataset, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model saving"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x7f17a0355c90>]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# generator.save('models/tf')\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtfjs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_keras_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodels/tfjs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/intero-ai-DBWhAuGQ/lib/python3.10/site-packages/tensorflowjs/converters/keras_h5_conversion.py:347\u001B[0m, in \u001B[0;36msave_keras_model\u001B[0;34m(model, artifacts_dir, quantization_dtype_map, weight_shard_size_bytes, metadata)\u001B[0m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Save a Keras model and its weights in TensorFlow.js format.\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \n\u001B[1;32m    322\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;124;03m  ValueError: If `artifacts_dir` already exists as a file (not a directory).\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    346\u001B[0m temp_h5_path \u001B[38;5;241m=\u001B[39m tempfile\u001B[38;5;241m.\u001B[39mmktemp() \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 347\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemp_h5_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m topology_json, weight_groups \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    349\u001B[0m     h5_merged_saved_model_to_tfjs_format(temp_h5_path))\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(artifacts_dir):\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/intero-ai-DBWhAuGQ/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/intero-ai-DBWhAuGQ/lib/python3.10/site-packages/keras/saving/hdf5_format.py:988\u001B[0m, in \u001B[0;36m_legacy_weights\u001B[0;34m(layer)\u001B[0m\n\u001B[1;32m    986\u001B[0m weights \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mtrainable_weights \u001B[38;5;241m+\u001B[39m layer\u001B[38;5;241m.\u001B[39mnon_trainable_weights\n\u001B[1;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(w, tf\u001B[38;5;241m.\u001B[39mVariable) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m weights):\n\u001B[0;32m--> 988\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    989\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSave or restore weights that is not an instance of `tf.Variable` is \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    990\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot supported in h5, use `save_format=\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m` instead. Received a \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    991\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel or layer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with weights \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweights\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m weights\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x7f17a0355c90>]"
     ]
    }
   ],
   "source": [
    "# generator.save('models/tf')\n",
    "tfjs.converters.save_keras_model(generator, 'models/tfjs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}